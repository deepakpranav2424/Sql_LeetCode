import org.apache.spark.SparkContext
import org.apache.log4j.Level
import org.apache.log4j.Logger

object WordCount extends App {

  Logger.getLogger("org").setLevel(Level.ERROR)
  
  val sc = new SparkContext("local[*]", "wordcount")

  val input = sc.textFile("C:/Users/deepa/Downloads/search_data.txt")

  val words = input.flatMap(x => x.split(" "))
  
  val wordsLower = words.map(x => x.toLowerCase())

  val wordMap = wordsLower.map(x => (x, 1))

  val wordCount = wordMap.reduceByKey((x, y) => x + y)
  
  
  //.sortBy(x => x._2,false)
  
  
  for(results <- wordCount){
    
   val word = results._1
   val count = results._2
    
  println(s"$word : $count")
  }
 
}